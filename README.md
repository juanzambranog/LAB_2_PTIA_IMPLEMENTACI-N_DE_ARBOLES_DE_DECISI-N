# ðŸŒ³ Laboratorio: Entrenamiento y EvaluaciÃ³n de Modelos de ClasificaciÃ³n (Decision Trees)
## Escuela Colombiana de IngenierÃ­a Julio Garavito
## Juan David Zambrano Gonzalez

## ðŸ“˜ DescripciÃ³n general

Este proyecto tiene como objetivo **entrenar, evaluar y comparar modelos de clasificaciÃ³n supervisada** utilizando el conjunto de datos **Adult Census Income (adult.data)**.  
Se busca determinar si una persona gana mÃ¡s o menos de 50K al aÃ±o en funciÃ³n de caracterÃ­sticas socioeconÃ³micas, aplicando **Ãrboles de DecisiÃ³n**, **Bosques Aleatorios (Random Forest)** y **Gradient Boosting**.

El laboratorio forma parte de las prÃ¡cticas de aprendizaje automÃ¡tico y se enfoca en la comprensiÃ³n de los procesos de **entrenamiento, validaciÃ³n, prueba y evaluaciÃ³n de desempeÃ±o** mediante mÃ©tricas como **F1-score** y **exactitud (accuracy)**.

---

## ðŸ” Dataset

El **dataset Adult** proviene de la base de datos del *Census Bureau* y contiene informaciÃ³n sobre edad, nivel educativo, ocupaciÃ³n, estado civil, horas trabajadas, entre otras variables.

**Objetivo:** predecir si una persona tiene un ingreso `>50K` o `<=50K`.

**Cantidad de registros:**
- Entrenamiento: 80%
- Prueba: 20%

**NÃºmero de atributos:** 14 caracterÃ­sticas (numÃ©ricas y categÃ³ricas).

---

## ðŸ§  Modelos implementados

### 1. Ãrbol de DecisiÃ³n (Decision Tree)
- Criterio: `entropy`
- Profundidad mÃ¡xima: `10`
- MÃ©trica: **F1-score = 0.654**

Permite observar la estructura jerÃ¡rquica de decisiones y entender cÃ³mo se dividen los datos segÃºn su ganancia de informaciÃ³n.

---

### 2. Bosque Aleatorio (Random Forest)
- NÃºmero de Ã¡rboles: `100`
- Criterio: `entropy`
- MÃ©trica: **F1-score = 0.676**

Reduce la varianza respecto al Ã¡rbol simple y mejora la generalizaciÃ³n combinando mÃºltiples Ã¡rboles de decisiÃ³n.

---

### 3. Gradient Boosting
- NÃºmero de estimadores: `100`
- Tasa de aprendizaje: `0.1`
- Profundidad mÃ¡xima: `3`
- MÃ©trica: **F1-score = 0.689**

Este modelo mostrÃ³ el **mejor desempeÃ±o** en la validaciÃ³n y prueba, alcanzando una precisiÃ³n promedio del **87%**. Combina Ã¡rboles de decisiÃ³n dÃ©biles que se ajustan progresivamente a los errores de los anteriores.

---

## ðŸ§© MetodologÃ­a

1. **Preprocesamiento de datos**
   - Manejo de valores faltantes.
   - CodificaciÃ³n de variables categÃ³ricas con `OneHotEncoder`.
   - NormalizaciÃ³n de variables numÃ©ricas con `StandardScaler`.

2. **DivisiÃ³n de datos**
   - 80% entrenamiento / 20% prueba.
   - Se utilizÃ³ un conjunto de **validaciÃ³n** adicional para seleccionar el mejor modelo.

3. **Entrenamiento de modelos**
   - ImplementaciÃ³n de los tres modelos en `scikit-learn`.
   - Ajuste de hiperparÃ¡metros bÃ¡sicos.

4. **EvaluaciÃ³n**
   - MÃ©tricas: F1-score, precisiÃ³n, recall y accuracy.
   - ComparaciÃ³n de desempeÃ±o entre modelos.
   - SelecciÃ³n del modelo con mejor F1-score (Gradient Boosting).

---

## ðŸ“ˆ Resultados comparativos

| Modelo              | Accuracy | F1-score | Observaciones                            |
|---------------------|-----------|-----------|-------------------------------------------|
| Ãrbol de DecisiÃ³n   | 0.85      | 0.654     | MÃ¡s interpretable, pero mayor varianza.   |
| Bosque Aleatorio    | 0.86      | 0.676     | Mejor generalizaciÃ³n y menor sobreajuste. |
| Gradient Boosting   | 0.87      | 0.689     | Mejor desempeÃ±o global. Modelo elegido.   |

---

## ðŸ§¾ Conclusiones

- El modelo **Gradient Boosting** fue el mÃ¡s preciso, mostrando mejor equilibrio entre sesgo y varianza.
- El **Ãrbol de DecisiÃ³n** sirviÃ³ como base conceptual para entender los demÃ¡s modelos.
- El **Bosque Aleatorio** mejorÃ³ la estabilidad de las predicciones, pero no superÃ³ al boosting en F1.
- Se confirma que los mÃ©todos de *ensemble* logran una mayor capacidad predictiva en problemas de clasificaciÃ³n con datos heterogÃ©neos.

---

## ðŸ‘¥ Equipo de trabajo

- Juan David Zambrano  

**Tiempo total invertido:** 7 horas  
**Estado del laboratorio:** Completo âœ…

---

## ðŸ“š Referencias

- Scikit-learn Developers. (2024). *Scikit-learn Documentation*. https://scikit-learn.org/stable/  
- GÃ©ron, A. (2022). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* (3rd ed.). O'Reilly Media.  
- IBM. (2023). *Decision Trees and Ensemble Methods in Machine Learning*. IBM Developer. https://developer.ibm.com/

---

## ðŸ’¡ Licencia

Este proyecto se distribuye bajo la licencia **MIT**. Puedes usar, modificar o compartir el cÃ³digo con fines educativos y de investigaciÃ³n.
